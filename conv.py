import requests
from bs4 import BeautifulSoup as bs
import json
from lxml import etree
from telegram import ParseMode
from telegram.ext import CallbackContext
from telegram import Update
from telegram.ext import Updater
from telegram.ext import MessageHandler
from telegram.ext import Filters






headers = {'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
           'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.117 YaBrowser/20.2.0.1043 Yowser/2.5 Safari/537.36'}
proxy = {'htpp': 'htpp://95.141.193.14:80', 'htpp://46.235.53.26:3128'
         'htpps':'htpp://95.141.193.14:80'}

def check_url(link):
    link = str(link)
    link = link.strip()
    if ('https://' or 'http://') not in link:
        link = ''.join(['https://', link])
    session = requests.Session()
    if ('asos' in link):
        request = session.get(link, headers=headers)
        if (request.status_code == 200):
            soup = bs(request.content, 'lxml')

            id = soup.find('link', attrs={'rel': 'alternate'})['href']
            if 'prd' in id:
                T = True
                i = len(id) - 1
                newID = ''
                while '/' not in newID:
                    newID += id[i]
                    i -= 1
                newID = newID[len(newID) - 2::-1]
            else:
                newID = ''
                T = False
        else:
            soup = 'None'
            T = False
    else:
        T = False
        newID = 'None'
        soup = 'None'

    return newID, T, soup, session


def get_all_urls(id):
    asos = 'asos.su/'
    all_urls = []
    valuet = ['RUB', 'GBP', 'AUD', 'TWD', 'HKD', 'ILS', 'CNY', 'TRR', 'EUR', 'SEK', 'CHF', 'EEG']
    for i in range(len(valuet)):
        url = ''.join([asos, valuet[i], id])
        all_urls.append(url)
    return all_urls



def get_urlsJs(id):
    regions = ['RU', 'COM', 'AU', 'ROW', 'ROW', 'ROW', 'ROW', 'ROW', 'DE', 'SE', 'FR', 'ROE']
    valuet = ['RUB', 'GBP', 'AUD', 'TWD', 'HKD', 'ILS', 'CNY', 'RUB', 'EUR', 'SEK', 'CHF', 'GBP']
    linksJs = []

    for i in range(len(regions)):
        NewLinks = ''.join(['https://www.asos.com/api/product/catalogue/v3/stockprice?productIds=', id, '&store=',  regions[i], '&currency=',  valuet[i], '&keyStoreDataversion=ekbycqu-23'])
        linksJs.append(NewLinks)
    return linksJs, valuet




def asos_parser_bot(linksJs, all_urls, headers, valuet, session, soup):
    goods = []
    conuntryList = ['RU', 'GB', 'AU', 'TW', 'HK', 'IL', 'CN', 'TR', 'DE', 'SE', 'FR', 'EE']
    for i in range(len(all_urls)):

        country = conuntryList[i]

        requestPrice = session.get(linksJs[i], headers=headers)
        soupJs = bs(requestPrice.content, 'lxml')
        soupJs = str(soupJs)
        root = etree.fromstring(soupJs)
        price = json.loads(root.xpath('.//p')[0].text)
        price = price[0]['productPrice']['current']['value']

        if i == 1:
            name = soup.find('h1').text
            goods.append({'name': name})

        goods.append({
            'country': country,
            'price': float(price),
            'valuet': valuet[i],
            'url': all_urls[i]
            })
    return goods



def get_cours(headers, session):
    url = 'https://pokur.su/gbp/'

    request = session.get(url, headers=headers)
    soup = bs(request.content, 'lxml')
    cours = []
    valuet = ['rub', 'aud', 'twd', 'hkd', 'ils', 'cny', 'eur', 'sek', 'chf']
    for i in range(len(valuet)):
        link = ''.join(['/gbp/', valuet[i], '/1/'])
        a = soup.find('a', attrs={'href': link}).text
        if ',' in a:
            a = float(a.replace(',', '.'))
        cours.append({
            valuet[i].upper(): a
        })
    return cours




def result(cours, goods):
    for i in range(2, len(goods)):
        val = goods[i].get('valuet')
        pr = goods[i].get('price')
        rub = cours[0].get('RUB')
        if val == 'GBP':
            res = float('{:.2f}'.format(pr * rub))
        else:
            for j in range(len(cours)):
                cr = cours[j].get(val)
                if cr != None:
                    a = cr
                    res = float('{:.2f}'.format(pr / a * rub))
        goods[i]['rub'] = res
    goods[0]['rub'] = goods[0].get('price')

    return goods


def sort(goods):
    name = str(goods[1].get('name'))
    goods.pop(1)
    for i in range(len(goods)):
        for j in range(len(goods)-i-1):
            if goods[j].get('rub') < goods[j+1].get('rub'):
                goods[j], goods[j+1] = goods[j+1], goods[j]
    return goods, name

def prinT(goods,name):
    print(name)
    s = '*'+name+'*'+'\n'
    bl = " " * 24
    print(bl)
    for i in range(len(goods)):
        s += ''.join([f'\n {goods[i].get("country")} \t\t {goods[i].get("rub")} \t\t ‚úîÔ∏è{goods[i].get("price"):}  ({goods[i].get("valuet")}): \n {bl}  {goods[i].get("url")}'])
    s += 'üëàüèª'
    res = goods[0].get('rub')
    k = 0
    for i in range(len(goods)-1):
        if res > goods[i+1].get('rub'):
            res = goods[i+1].get('rub')
            k = i + 1
    content = ['',
               '',
               f'‚òùüèª–õ—É—á—à–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ {goods[k].get("country")} - {res} —Ä—É–±, –æ–ø–ª–∞—Ç–∞ –≤ {goods[k].get("valuet")}.',
               '(–í—Å–µ —Ü–µ–Ω—ã –≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ RUB).ü§üüèª',
                '–≠–∫–æ–Ω–æ–º—å –µ—â—ë –±–æ–ª—å—à–µ —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º–∏ –ø—Ä–æ–º–æ–∫–æ–¥–∞–º–∏ ASOSüëçüèª',
               '',
               'üîπ–û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å: [telegram](http://tgram.su/xexeel)']

    s += '\n'.join(content)
    return s


def get_url(update: Update, context: CallbackContext):
    link = update.effective_message.text
    if link == '/start':
        text = ['–ü—Ä–∏–≤–µ—Ç!',
                '',
                '–Ø –±—ã–ª —Å–æ–∑–¥–∞–Ω –¥–ª—è –ø–æ–º–æ—â–∏ –≤ –ø–æ–∫—É–ø–∫–∞—Ö –Ω–∞ ASOS.COM.',
                '–ó–Ω–∞–µ—à—å –ª–∏ —Ç—ã, —á—Ç–æ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ —Ç–æ–≤–∞—Ä',
                '–∏–º–µ–µ—Ç —Ä–∞–∑–Ω—ã–µ —Ü–µ–Ω—ã –Ω–∞ —Å–∞–π—Ç–∞—Ö ASOS, –æ—Ç–Ω–æ—Å—è—â–∏—Ö—Å—è –∫ —Ä–∞–∑–Ω—ã–º —Å—Ç—Ä–∞–Ω–∞–º',
                '–Ø —Å–∫–∞–Ω–∏—Ä—É—é —Ü–µ–Ω—ã –Ω–∞ –≤—Å–µ—Ö ASOS-—Å–∞–π—Ç–∞—Ö',
                '–∏ —Å—Ä–∞–≤–Ω–∏–≤–∞—é –∏—Ö –≤ –≤—ã–±—Ä–∞–Ω–æ–π –≤–∞–ª—é—Ç–µ.',
                '–£–∑–Ω–∞–π, –≥–¥–µ –ø—Ä–æ–¥—É–∫—Ç –∏–º–µ–µ—Ç —Å–∞–º—É—é –Ω–∏–∑–∫—É—é —Ü–µ–Ω—É,–∏ –≤ –∫–∞–∫–æ–π –≤–∞–ª—é—Ç–µ',
                '–≤—ã–≥–æ–¥–Ω–µ–µ –≤—Å–µ–≥–æ —Å–æ–≤–µ—Ä—à–∏—Ç—å –ø–æ–∫—É–ø–∫—É!',
                '',
                '–û—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã, —Ü–µ–Ω—ã –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ —Ö–æ—á–µ—à—å —Å—Ä–∞–≤–Ω–∏—Ç—å!',
                '',
                '–ß–∏—Ç–∞–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é [üëâüèª–∑–¥–µ—Å—åüëàüèª](https://teletype.in/@edima/R5BateM_H)',
                '',
                '–ö–æ–Ω—Ç–∞–∫—Ç—ã:',
                '[telegram](http://tgram.su/xexeel)',
                '[vk](https://vk.com/e_dima)',
                '',
                '']
        update.message.reply_text(
            text='\n'.join(text),
            parse_mode=ParseMode.MARKDOWN,
        )
    elif link == '/help':
        text = ['–í —Å–ª—É—á–∞–∏–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –ø—Ä–æ–±–ª–µ–º —á–∏—Ç–∞–π—Ç–µ FAQ ',
                '[üëâüèª–∑–¥–µ—Å—åüëàüèª](https://teletype.in/@edima/R5BateM_H)',
                '',
                '–ï—Å–ª–∏ –≤—ã –Ω–µ —Å–º–æ–≥–ª–∏ —Ä–µ—à–∏—Ç—å —Å–≤–æ—é –ø—Ä–æ–±–µ–ª–º—É, —Å–≤—è–∂–∏—Ç–µ—Å—å —Å–æ –º–Ω–æ–π',
                '',
                '–ö–æ–Ω—Ç–∞–∫—Ç—ã:',
                'üîπ [telegram](http://tgram.su/xexeel)',
                'üîπ [vk](https://vk.com/e_dima)',
                '',
                '']
        update.message.reply_text(
            text='\n'.join(text),
            parse_mode=ParseMode.MARKDOWN,
        )
    else:
        id, T, soup, session = check_url(link,)
        if T:
            update.message.reply_text(
                text='–ù–∞–π–¥–µ–Ω–∞ 1 –ø–æ–∑–∏—Ü–∏—è. –ü–æ–¥–æ–∂–¥–∏—Ç–µ, –∏–¥–µ—Ç –ø–æ–∏—Å–∫ —Ü–µ–Ω...'
            )
            all_urls = get_all_urls(id)
            update.message.reply_text(
                text=id
            )
            linksJs, valuet = get_urlsJs(id)
            update.message.reply_text(
                text=(linksJs,
                      valuet)
            )
            cours = get_cours(headers, session)
            update.message.reply_text(
                text='4...')
            goods = asos_parser_bot(linksJs, all_urls, headers, valuet, session, soup)
            update.message.reply_text(
                text='3...'
            )
            result(cours, goods)
            update.message.reply_text(
                text='5...')
            goods, name = sort(goods)
            update.message.reply_text(
                text='6...')
            end = prinT(goods,name)
            update.message.reply_text(
                text=end,
                parse_mode=ParseMode.MARKDOWN,
               )
        else:
            update.message.reply_text(
                text='–û—à–∏–±–∫–∞. –ù–µ –º–æ–≥—É –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —ç—Ç—É —Å—Å—ã–ª–∫—É.'
            )




def main():
    updater = Updater(
        token='1148579186:AAHnPRrZ8INOQVZkDErcdGlm5OLGXxQ9Q-E',
        base_url='https://telegg.ru/orig/bot',
        use_context=True,
    )
    updater.dispatcher.add_handler(MessageHandler(Filters.text, callback=get_url))
    updater.start_polling()
    updater.idle()
if __name__ == '__main__':
    main()
